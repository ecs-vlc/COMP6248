\ifdefined\beamerclass
\else
    \def\beamerclass{beamer}
\fi
\documentclass[\beamerclass]{beamer}

\usepackage{pgfpages}
\mode<handout>{
  % \setbeamercolor{background canvas}{bg=black!20}
  \pgfpagesuselayout{2 on 1}[a4paper,border shrink=5mm]
}

\usepackage{lmodern}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{textpos} % package for the positioning

\usepackage{pgf, tikz}
\usetikzlibrary{arrows, automata}

\usetheme{Copenhagen}
\hypersetup{pdfstartview={Fit}}
\lstset{basicstyle=\small\ttfamily,breaklines=true}

\usepackage[english]{babel}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
%\graphicspath{{./images/}}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows,chains}
\usepackage{booktabs,makecell,multirow,tabularx}
\usepackage{verbatim}
\renewcommand{\arraystretch}{1.2}
\renewcommand\theadfont{\normalfont\bfseries}
\usepackage{array}
\usepackage{listings}
\lstset{language=Java, showstringspaces=false}
\usepackage[normalem]{ulem}
\usepackage{bm}
\def\layersep{2.5cm}

\usepackage{xcolor}
%\usepackage{subfig}
\setbeamertemplate{caption}{\insertcaption}
\usepackage[caption=false]{subfig}
\usepackage{hyperref}
\usepackage{verbatim}
%\setbeamertemplate{caption}[numbered]%\numberwithin{figure}{section}
% Define block styles
\tikzstyle{decision} = [diamond, draw, fill=blue!20, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=3em, text centered, rounded corners, minimum height=3em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse, fill=red!20, node distance=3cm,
    minimum height=2em]
\tikzset{
  startstop/.style={
    rectangle, 
    rounded corners,
    minimum width=3cm, 
    minimum height=1cm,
    align=center, 
    draw=black, 
    fill=red!30
    },
  process/.style={
    rectangle, 
    minimum width=3cm, 
    minimum height=1cm, 
    align=center, 
    draw=black, 
    fill=blue!30
    },
  decision/.style={
    rectangle, 
    minimum width=3cm, 
    minimum height=1cm, align=center, 
    draw=black, 
    fill=green!30
    },
  arrow/.style={thick,->,>=stealth},
  dec/.style={
    ellipse, 
    align=center, 
    draw=black, 
    fill=green!30
    },
}
\tikzstyle{arrow} = [thick,->,>=stealth]

\tikzset{onslide/.code args={<#1>#2}{%
  \only<#1>{\pgfkeysalso{#2}} % \pgfkeysalso doesn't change the path
}}

\makeatletter
\newenvironment<>{btHighlight}[1][]
{\begin{onlyenv}#2\begingroup\tikzset{bt@Highlight@par/.style={#1}}\begin{lrbox}{\@tempboxa}}
{\end{lrbox}\bt@HL@box[bt@Highlight@par]{\@tempboxa}\endgroup\end{onlyenv}}

\newcommand<>\btHL[1][]{%
  \only#2{\begin{btHighlight}[#1]\bgroup\aftergroup\bt@HL@endenv}%
}
\def\bt@HL@endenv{%
  \end{btHighlight}%   
  \egroup
}
\newcommand{\bt@HL@box}[2][]{%
  \tikz[#1]{%
    \pgfpathrectangle{\pgfpoint{1pt}{0pt}}{\pgfpoint{\wd #2}{\ht #2}}%
    \pgfusepath{use as bounding box}%
    \node[anchor=base west, fill=orange!30,outer sep=0pt,inner xsep=1pt, inner ysep=0pt, rounded corners=3pt, minimum height=\ht\strutbox+1pt,#1]{\raisebox{1pt}{\strut}\strut\usebox{#2}};
  }%
}
\makeatother

\definecolor{darkblue}{RGB}{37,55,97}
\definecolor{mellowyellow}{RGB}{247,206,70}
\definecolor{almostwhite}{RGB}{254,255,255}
\definecolor{merrygreen}{RGB}{79,173,91}
\definecolor{funkyorange}{RGB}{240,154,56}

\addtobeamertemplate{footnote}{\hskip -2em}{}
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\DeclareMathOperator{\softmax}{softmax}
\DeclareMathOperator{\ReLU}{ReLU}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Formatting for title page
\title[Optimisation]{Optimisation}
\author{Jonathon Hare}  
\institute[]
{
  Vision, Learning and Control\\
  University of Southampton 
}
\date{}
\subject{Computer Science}
\useoutertheme{infolines}
\setbeamertemplate{headline}{} %remove headline
\setbeamertemplate{navigation symbols}{} %remove navigation symbols

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{frame}[plain]
  \begin{tikzpicture}[overlay, remember picture, shift={(current page.south west)},font={\fontfamily{Montserrat-TOsF}\selectfont}]
  \fill [mellowyellow,text=darkblue] (0,0) rectangle (\paperwidth, \paperheight);
  \draw (4,7) node [align=left,text=darkblue] {\Huge \begin{tabular}{l} \textbf{Minimise} \\ \textbf{your} \\ \textbf{Loss} \end{tabular}};
  \draw (11,1) node [align=left,text=darkblue] {\includegraphics[scale=0.15]{../vlc.png}};
  \end{tikzpicture}
\end{frame}


\begin{frame}
  \titlepage%\footnote{Some of the material in this lecture is based on Andrew Ng's lectures on Optimisation} %% \url{https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf }} 
\end{frame}
%%-------------------------------------------------------------%

\begin{frame}
  \frametitle{Gradient descent and SGD (again), and mini-batch SGD}
  
  We'll start up by looking again at gradient descent algorithms and their behaviours...
\end{frame}

%-------------------------------------------------------------%
\begin{frame}[fragile]\frametitle{Reminder: Gradient Descent}

\begin{itemize}
  \item Define total loss as $\mathcal{L} = -\sum_{(\bm x,y) \in \bm D} \ell(g(\bm x,\bm\theta), y)$ for some loss function $\ell$, dataset $\bm D$ and model $g$ with learnable parameters $\bm\theta$.
  \item Define how many passes over the data to make (each one known as an Epoch)
  \item Define a learning rate $\eta$
\end{itemize}

Gradient Descent updates the parameters $\bm\theta$ by moving them in the direction of the negative gradient with respect to the \textbf{total loss} $\mathcal{L}$ by the learning rate $\eta$ multiplied by the gradient:
\\[1em]
\hspace{1cm} \texttt{for each Epoch:}\\
\hspace{2cm} $\bm\theta \leftarrow \bm\theta - \eta \nabla_{\bm\theta} \mathcal{L}$
\end{frame}

%-------------------------------------------------------------%

\begin{frame}[fragile]\frametitle{Gradient Descent}
\begin{itemize}
  \item Gradient Descent has good statistical properties (very low variance)
  \item But is very data inefficient (particularly when data has many similarities)
  \item Doesn't scale to effectively infinite data (e.g. with augmentation)
\end{itemize}
\end{frame}

%-------------------------------------------------------------%

\begin{frame}[fragile]\frametitle{Reminder: Stochastic Gradient Descent}

\begin{itemize}
  \item Define loss function $\ell$, dataset $\bm D$ and model $g$ with learnable parameters $\bm\theta$.
  \item Define how many passes over the data to make (each one known as an Epoch)
  \item Define a learning rate $\eta$
\end{itemize}

Stochastic Gradient Descent updates the parameters $\bm\theta$ by moving them in the direction of the negative gradient with respect to the loss of a \textbf{single item} $\ell$ by the learning rate $\eta$ multiplied by the gradient:
\\[1em]
\hspace{1cm} \texttt{for each Epoch:}\\
  \hspace{2cm} \texttt{for each $(\bm x,y) \in \bm D$:}\\
    \hspace{3cm} $\bm\theta \leftarrow \bm\theta - \eta \nabla_{\bm\theta} \ell$
\end{frame}

%-------------------------------------------------------------%

\begin{frame}[fragile]\frametitle{Stochastic Gradient Descent}
\begin{itemize}
  \item Stochastic Gradient Descent has poor statistical properties (very high variance)
  \item But is computationally inefficient (poor utilisation of resources - particularly with respect to vectorisation)
\end{itemize}
\end{frame}

%-------------------------------------------------------------%

\begin{frame}[fragile]\frametitle{Mini-batch Stochastic Gradient Descent}

\begin{itemize}
  \item Define a batch size $b$
  \item Define batch loss as $\mathcal{L}_b = -\sum_{(\bm x,y) \in \bm D_b} \ell(g(\bm x,\bm\theta), y)$ for some loss function $\ell$and model $g$ with learnable parameters $\bm\theta$. $\bm D_b$ is a subset of dataset $\bm D$ of cardinality $b$.
  \item Define how many passes over the data to make (each one known as an Epoch)
  \item Define a learning rate $\eta$
\end{itemize}

Mini-batch Gradient Descent updates the parameters $\bm\theta$ by moving them in the direction of the negative gradient with respect to the loss of a \textbf{mini-batch} $\bm D_b$, $\mathcal{L}_b$ by the learning rate $\eta$ multiplied by the gradient:
\\[1em]
\hspace{1cm}partition the dataset $\bm D$ into an array of subsets of size $b$\\
\hspace{1cm} \texttt{for each Epoch:}\\
  \hspace{2cm} \texttt{for each $\bm D_b \in partitioned(\bm D$):}\\
      \hspace{3cm} $\bm\theta \leftarrow \bm\theta - \eta \nabla_{\bm\theta} \mathcal{L}_b$
\end{frame}

%-------------------------------------------------------------%

\begin{frame}[fragile]\frametitle{Mini-batch Stochastic Gradient Descent}
\begin{itemize}
  \item<1-> Mini-batch Stochastic Gradient Descent has reasonable statistical properties (much lower variance than SGD)
  \item<1-> Allows for computationally efficiency (good utilisation of resources)
  \item<2-> Ultimately we would normally want to make our batches as big as possible for lower variance gradient estimates, but:
  \begin{itemize}
    \item Must still fit in RAM (e.g. on the GPU)
    \item Must be able to maintain throughput (e.g. pre-processing on the CPU; data transfer time)
  \end{itemize}
\end{itemize}
\end{frame}

%-------------------------------------------------------------%

\begin{frame}\frametitle{So, what about the learning rate?}

\begin{itemize}
\item<+-> Choice of learning rate is extremely important
\item<+-> But we have to reason about the `loss landscape'
\begin{itemize}
  \item<+-> Most convergence analysis of optimisation algorithms assumes a convex loss landscape
  \begin{itemize}
    \item Easy to reason about
    \item Can be shown that (S)GD will converge to the optimal solution for a variety of learning rates
    \item Can give insights into potential problems in the non-convex case
  \end{itemize}
  \item<+-> Deep Learning is highly non-convex
  \begin{itemize}
    \item<+-> Many local minima
    \item<+-> Plateaus
    \item<+-> Saddle points
    \item<+-> Symmetries (permutation, etc)
    \item<+-> Certainly no single global minima
  \end{itemize}
\end{itemize}
\end{itemize}
\end{frame}

%-------------------------------------------------------------%

\begin{frame}[fragile]\frametitle{*GD in the convex case: failure modes}

% \begin{itemize}
% \item If the ellipse is very elongated, the direction of steepest descent is almost perpendicular to the direction towards the minimum
% \item The gradient vector will have a large component along the short axis of the ellipse and a small component along the long axis of the ellipse.
% \item This is the opposite of what we want to optimise efficiently
% \end{itemize}

\includegraphics[width=\textwidth]{contours.pdf}

\end{frame}

%-------------------------------------------------------------%

\begin{frame}\frametitle{Accelerated Gradient Methods}

\begin{itemize}
  \item<+-> Accelerated gradient methods use a \emph{leaky} average of the gradient, rather than the instantaneous gradient estimate at each time step
  \item<+-> A physical analogy would be one of the momentum a ball picks up rolling down a hill...
  \item<+-> As you'll see, this helps address the *GD failure modes, but also helps avoid getting stuck in local minima
\end{itemize}

\end{frame}

%-------------------------------------------------------------%

\begin{frame}{pause}\frametitle{Momentum I}

It's common for the `leaky' average (the `velocity', $v_t$) to be a weighted average of the instantaneous gradient $g_t$ and the past velocity\footnote{There are quite a few variants of this; here we're following the PyTorch variant}:

\begin{equation*}
  v_t = \beta v_{t-1} + g_t
\end{equation*}

where $\beta \in [0,1]$ is the `momentum'.

\end{frame}
%-------------------------------------------------------------%


%\begin{frame}[fragile]\frametitle{ Motivating Momentum}
%\url{https://www.youtube.com/watch?v=7HZk7kGk5bU&t=172s}
%\end{frame}
%-------------------------------------------------------------%

\begin{frame}[fragile]\frametitle{Momentum II}
\begin{itemize}
\item The momentum method allows to accumulate velocity in directions of low curvature that
persist across multiple iterations
\item This leads to accelerated progress in low curvature directions compared to gradient descent %\footnote{\url{http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf}}
\end{itemize}
\end{frame}
%-------------------------------------------------------------%

\begin{frame}[fragile]\frametitle{MB-SGD with Momentum}

Learning with momentum on iteration $t$ (batch at $t$ denoted by $b(t)$) is given by:
\begin{align*}
\bm v_t & \leftarrow \beta \bm v_{t-1} + \nabla_{\bm\theta} \mathcal{L}_{b(t)} \\
\bm\theta_t & \leftarrow \bm\theta_{t-1} - \eta \bm v_t
\end{align*}

Note $\beta = 0.9$ is a good choice for the momentum parameter.
\end{frame}
%-------------------------------------------------------------%

\begin{frame}\frametitle{SGD with Momentum - potentially better convex convergence}
\includegraphics[width=\textwidth]{contours.pdf}
\end{frame}
%-------------------------------------------------------------%
\begin{frame}\frametitle{Learning rate schedules}

\begin{itemize}
  \item<+-> In practice you want to decay your learning rate over time
  \item<+-> Smaller steps will help you get closer to the minima
  \item<+-> But don't do it to early, else you might get stuck
  \item<+-> Something of an art form!
  \begin{itemize}
    \item `Grad Student Descent' or GDGS (`Gradient Descent by Grad Student`)
  \end{itemize}
\end{itemize}

\end{frame}
%-------------------------------------------------------------%
\begin{frame}\frametitle{Reduce LR on plateau}
\begin{itemize}
  \item Common Heuristic approach:
  \begin{itemize}
    \item if the loss hasn't improved (within some tolerance) for $k$ epochs
    \item then drop the lr by a factor of 10
  \end{itemize}
  \item Remarkably powerful!
\end{itemize}
\end{frame}

%-------------------------------------------------------------%

\begin{frame}\frametitle{Cyclic learning rates}
\begin{itemize}
  \item<+-> Worried about getting stuck in a non-optimal local minima?
  \item<+-> Cycle the learning rate up and down (possibly annealed), with a different lr on each batch
  \item<+-> See \url{https://arxiv.org/abs/1506.01186}
\end{itemize}
\end{frame}

%-------------------------------------------------------------%
\begin{frame}\frametitle{More advanced optimisers}

\begin{itemize}
  \item<+-> Adagrad
  \begin{itemize}
    \item Decrease learning rate dynamically per weight.
    \item Squared magnitude of the gradient (2nd moment) used to adjust how quickly progress is made - weights with large gradients are compensated with a smaller learning rate.
    \item Particularly effective for sparse features.
  \end{itemize}
  \item<+-> RMSProp
  \begin{itemize}
    \item Modifies Adagrad to decouple learning rate from gradient magnitude scaling
    \item Incorporates leaky averaging of squared gradient magnitudes
    \item LR would typically follow a predefined schedule
  \end{itemize}
  \item<+-> Adam
  \begin{itemize}
    \item Essentially takes all the best ideas from RMSProp and SDG+Momentum
    \item Bias corrected momentum and second moment estimation
    \item Shown that it might still diverge (or be non optimal, even in convex settings)...
    \item LR is still a hyperparameter (you might still schedule)
  \end{itemize}
\end{itemize}

\end{frame}
%-------------------------------------------------------------%

\begin{frame}\frametitle{Take-away messages}

\begin{itemize}
  \item The loss landscape of a deep network is complex to understand (and is far from convex)
  \item If you're in a hurry to get results use Adam
  \item If you have time (or a Grad Student at hand), then use SGD (with momentum) and work on tuning the learning rate
  \item If you're implementing something from a paper, then follow what they did!
\end{itemize}

\end{frame}
%-------------------------------------------------------------%

% \begin{frame}[fragile]\frametitle{RMSProp}
% Learning with RMSProp is given by \vspace{5mm}

% On iteration $t$: \\
% \hspace{3mm} Compute $dW$ on current mini-batch \\
% \begin{eqnarray}
% && S_{dW_t} =  \beta S_{dW_{t-1}} + (1 - \beta) dW_t^2 \\
% && w_t = w_{t-1} - \eta \frac{dW_t}{\sqrt S_{dW_t}} 
% \end{eqnarray}

% \end{frame}
% %-------------------------------------------------------------%


% \begin{frame}{pause}\frametitle{Bias Correction Motivation}

% \begin{itemize}
% \item Let's  assume that $v_0 = 0$ and $\beta = 0.9$ and we're considering exponentially weighted averages \pause
% \item It follows that $v_1 = \beta (0) + (1 - \beta) \theta_1 = 0.1 \hspace{1mm} \theta_1$  \pause
% \item and $v_2 = \beta ( (1 - \beta) \theta_1) + (1-\beta) \theta_2 = 0.0196 \hspace{1mm} \theta_1 + 0.02 \hspace{1mm} \theta_2 $ \pause
% \end{itemize}
% \end{frame}
% %-------------------------------------------------------------%

% \begin{frame}{pause}\frametitle{Bias Correction }

% \begin{itemize}
% \item Add a bias correction term: $\frac{v_t}{1 - \beta^t} $\pause
% \item $t = 1$: $\frac{v_1}{1 - (0.9)^1} = 10 * v_1$ \pause
% \item $t = 2$: $\frac{v_2}{1 - (0.9)^2} = 5.263 * v_2$ \pause
% \item \dots
% \item $t = 10$: $\frac{v_{10}}{1 - (0.9)^{10}} = 1.535 * v_{10}$ 
% \item \dots
% \item $t = 20$: $\frac{v_{20}}{1 - (0.9)^{20}} = 1.138 * v_{20}$ 
% \end{itemize}
% \end{frame}
% %-------------------------------------------------------------%

% \begin{frame}[fragile]\frametitle{ Adam}
% Initialize parameters: $V_{dW} = 0, S_{dW} = 0$ \vspace{3mm}

% On iteration $t$: \\
% \hspace{3mm} Compute $dW_t$ on current mini-batch \\
% \begin{eqnarray}
% && V_{dW} =  \beta_1 V_{dW} + (1 - \beta_1) dW, \hspace{3mm} V_{dW}^{corr} = \frac{ V_{dW}} { (1 - \beta_1^t)}\\ 
% && S_{dW} =  \beta_2 S_{dW} + (1 - \beta_2) dW^2 , \hspace{3mm} S_{dW}^{corr} = \frac{ S_{dW}} { (1 - \beta_2^t)}\\ 
% && w := w - \eta \frac{V_{dW}^{corr}}{\sqrt (S_{dW}^{corr} + \epsilon)}
% \end{eqnarray}

% \end{frame}
%-------------------------------------------------------------%


\end{document}
